{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)\n",
    "\n",
    "# pull in vid_to_20 from savedFramesIn20\n",
    "# might not need to if videos are preprocessed\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "file_path = \"Images-Videos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestFrames1DIR = 'C:\\\\Users\\\\Fletcher\\\\Documents\\\\McDaniel\\\\Summer 2019 research\\\\Python Code\\\\Images-Videos\\\\TestFrames1.1_sample\\\\'\n",
    "\n",
    "CATEGORIES = ['ApplyEyeMakeup', 'ApplyLipstick', 'Archery', 'BabyCrawling', 'BalanceBeam', 'BandMarching',\n",
    "              'BaseballPitch', 'Basketball', 'BasketballDunk', 'BenchPress', 'Biking', 'Billiards', 'BlowDryHair',\n",
    "              'BlowingCandles', 'BodyWeightSquats', 'Bowling', 'BoxingPunchingBag', 'BoxingSpeedBag', 'Breaststroke',\n",
    "              'BrushingTeeth', 'CleanandJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'CuttingInKitchen',\n",
    "              'Diving', 'Drumming', 'Fencing', 'FieldHockeyPenalty', 'FloorGymnastics', 'FrisbeeCatch', 'FrontCrawl',\n",
    "              'GolfSwing', 'Haircut', 'HammerThrow', 'Hammering', 'HandstandPushups', 'HandstandWalking',\n",
    "              'HeadMassage', 'HighJump', 'HorseRace', 'HorseRiding', 'HulaHoop', 'IceDancing', 'JavelinThrow',\n",
    "              'JugglingBalls', 'JumpRope', 'JumpingJack', 'Kayaking', 'Knitting', 'LongJump', 'Lunges',\n",
    "              'MilitaryParade', 'Mixing', 'MoppingFloor', 'Nunchucks', 'ParallelBars', 'PizzaTossing',\n",
    "              'PlayingGuitar', 'PlayingPiano', 'PlayingTabla', 'PlayingViolin', 'PlayingCello', 'PlayingDaf',\n",
    "              'PlayingDhol', 'PlayingFlute', 'PlayingSitar', 'PoleVault', 'PommelHorse', 'PullUps', 'Punch',\n",
    "              'PushUps', 'Rafting', 'RockClimbingIndoor', 'RopeClimbing', 'Rowing', 'SalsaSpin', 'ShavingBeard',\n",
    "              'Shotput', 'SkateBoarding', 'Skiing', 'Skijet', 'SkyDiving', 'SoccerJuggling', 'SoccerPenalty',\n",
    "              'StillRings', 'SumoWrestling', 'Surfing', 'Swing', 'TableTennisShot', 'TaiChi', 'TennisSwing',\n",
    "              'ThrowDiscus', 'TrampolineJumping', 'Typing', 'UnevenBars', 'VolleyballSpiking', 'WalkingWithDog',\n",
    "              'WallPushups', 'WritingOnBoard', 'YoYo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ApplyEyeMakeup\n",
      "ApplyLipstick\n",
      "Archery\n",
      "BabyCrawling\n",
      "BalanceBeam\n",
      "BandMarching\n",
      "BaseballPitch\n",
      "Basketball\n",
      "BasketballDunk\n",
      "BenchPress\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "testing_data1 = []\n",
    "catNum = 0\n",
    "count = 0\n",
    "\n",
    "# iterate through each category\n",
    "for category in CATEGORIES:\n",
    "    # limit to a certain number of categories, later use all categories\n",
    "    if(catNum > 9):\n",
    "        break\n",
    "    \n",
    "    # update the path, print the name of the category\n",
    "    pathCat = os.path.join(TestFrames1DIR, category)\n",
    "    pathVid = TestFrames1DIR + str(category)\n",
    "    print(category)\n",
    "    \n",
    "    # iterate through each video\n",
    "    for video in os.listdir(pathVid):\n",
    "        pathImg = pathVid + '/' + str(video)\n",
    "        #print(video)\n",
    "        \n",
    "        # holds each frame\n",
    "        frame_set = []\n",
    "        \n",
    "        for img in os.listdir(pathImg):\n",
    "            img_array = cv2.imread(pathImg + '/' + img)\n",
    "            \n",
    "            # adds the frame to the array\n",
    "            #frame_set.append([np.array(img_array), catNum])\n",
    "            testing_data1.append([np.array(img_array), catNum])\n",
    "            \n",
    "        # adds the frame_set to the input array\n",
    "        #testing_data1.append([np.array(frame_set), catNum])\n",
    "            \n",
    "    catNum += 1\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3880, 227, 227, 3)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "#i=0\n",
    "#entry = []\n",
    "for features, label in testing_data1:\n",
    "    #entry.append()\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "    #i += 1\n",
    "\n",
    "X = np.array(X)\n",
    "# need to reshape to mark the videos distinctly\n",
    "X.reshape(20, 194, 227, 227, 3)\n",
    "print(X.shape)\n",
    "print(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take about 80% of the data for training\n",
    "train_limit = (int)(y.size * 0.8)\n",
    "\n",
    "X2 = X[:train_limit]\n",
    "y2 = y[:train_limit]\n",
    "plt.imshow(X2[1])\n",
    "plt.show()\n",
    "\n",
    "X2 /= 255.0\n",
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(?, 227, 227, 3) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input tensor for the CNN\n",
    "input1 = tf.keras.Input( shape=(227,227,3,) )\n",
    "input1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing adding the 20 frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## almost working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first convolutional layers\n",
    "# should each output shape 55x55x96\n",
    "frames = []\n",
    "\n",
    "for entry in X:    # the 20 frame array\n",
    "    for frame in entry:\n",
    "        frame_ = tf.keras.layers.Conv2D(96, 11, input_shape=(3, 227, 227), strides=4, activation='relu' )(frame)\n",
    "        frames += frame_\n",
    "\n",
    "\n",
    "# add the 20 frames into each other\n",
    "# should output shape 55x55x96 \n",
    "added = tf.keras.layers.Add()( frames )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this is the rest of the network, but can't test until input works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'added' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-17a0ffd92c8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# normalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnorm1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0madded\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# first pooling layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpool1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPool2D\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnorm1\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'added' is not defined"
     ]
    }
   ],
   "source": [
    "# normalization\n",
    "norm1 = layers.BatchNormalization()( added )\n",
    "# first pooling layer\n",
    "pool1 = layers.MaxPool2D( pool_size=3, strides=2 )( norm1 )\n",
    "\n",
    "\n",
    "# first 2D convolutional\n",
    "conv2 = layers.Conv2D( filters=23, kernel_size=256, strides=1 )( pool1 )\n",
    "# normalization\n",
    "norm2 = layers.BatchNormalization()(conv2)\n",
    "# second pooling\n",
    "pool2 = layers.MaxPool2D( pool_size=3, strides=2 )( norm2 )\n",
    "\n",
    "\n",
    "# third convolutional layer\n",
    "conv3 = layers.Conv2D( filters=9, kernel_size=384, strides=1 )( pool2 )\n",
    "# fourth convolutional\n",
    "conv4 = layers.Conv2D( filters=7, kernel_size=384, strides=1 )( conv3 )\n",
    "# fifth convolutional\n",
    "conv5 = layers.Conv2D( filters=5, kernel_size=256, strides=1 )( conv4 )\n",
    "# third pooling\n",
    "pool3 = layers.MaxPool2D( pool_size=3, strides=2 )( conv5 )\n",
    "\n",
    "# \n",
    "#model.add(Flatten())\n",
    "\n",
    "# three fully-connected layers\n",
    "fc1 = layers.Dense( units=512 )( pool3 ) # i reduced the number of units for testing on my laptop\n",
    "fc2 = layers.Dense( units=512 )( fc1 )\n",
    "fc3 = layers.Dense( units=101 )( fc2 )\n",
    "\n",
    "# softmax\n",
    "soft = layers.Activation( 'softmax' )( fc3 )\n",
    "\n",
    "model = tf.keras.Model( inputs=inputs, outputs=soft )\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X2, y2, batch_size = 32, epochs = 3, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictIMG = X[ train_limit : train_limit + 5 ]\n",
    "\n",
    "predict = model.predict(PredictIMG)\n",
    "\n",
    "i=0\n",
    "for item in predict:\n",
    "    plt.imshow( X[ train_limit + i ] )\n",
    "    plt.show()\n",
    "    print(predict[i])\n",
    "    print(CATEGORIES[ y[train_limit + i ] ])\n",
    "    i+=1\n",
    "\n",
    "\"\"\"\n",
    "plt.imshow(X[5500])\n",
    "plt.show()\n",
    "print(predict[0])\n",
    "print(CATEGORIES[y[5500]])\n",
    "\n",
    "plt.imshow(X[5501])\n",
    "plt.show()\n",
    "print(predict[1])\n",
    "print(CATEGORIES[y[5501]])\n",
    "\n",
    "\n",
    "plt.imshow(X[5502])\n",
    "plt.show()\n",
    "print(predict[2])\n",
    "print(CATEGORIES[y[5502]])\n",
    "\n",
    "\n",
    "plt.imshow(X[5503])\n",
    "plt.show()\n",
    "print(predict[3])\n",
    "print(CATEGORIES[y[5503]])\n",
    "\n",
    "\n",
    "plt.imshow(X[5504])\n",
    "plt.show()\n",
    "print(predict[4])\n",
    "print(CATEGORIES[y[5504]])\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
