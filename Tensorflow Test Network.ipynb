{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)\n",
    "\n",
    "# pull in vid_to_20 from savedFramesIn20\n",
    "# might not need to if videos are preprocessed\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "file_path = \"Images-Videos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestFrames1DIR = 'C:/Users/Fletcher/Documents/McDaniel/Summer 2019 research/Python Code/Images-Videos/'\n",
    "\n",
    "CATEGORIES = ['ApplyEyeMakeup', 'ApplyLipstick', 'Archery', 'BabyCrawling', 'BalanceBeam', 'BandMarching',\n",
    "              'BaseballPitch', 'Basketball', 'BasketballDunk', 'BenchPress', 'Biking', 'Billiards', 'BlowDryHair',\n",
    "              'BlowingCandles', 'BodyWeightSquats', 'Bowling', 'BoxingPunchingBag', 'BoxingSpeedBag', 'Breaststroke',\n",
    "              'BrushingTeeth', 'CleanandJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'CuttingInKitchen',\n",
    "              'Diving', 'Drumming', 'Fencing', 'FieldHockeyPenalty', 'FloorGymnastics', 'FrisbeeCatch', 'FrontCrawl',\n",
    "              'GolfSwing', 'Haircut', 'HammerThrow', 'Hammering', 'HandstandPushups', 'HandstandWalking',\n",
    "              'HeadMassage', 'HighJump', 'HorseRace', 'HorseRiding', 'HulaHoop', 'IceDancing', 'JavelinThrow',\n",
    "              'JugglingBalls', 'JumpRope', 'JumpingJack', 'Kayaking', 'Knitting', 'LongJump', 'Lunges',\n",
    "              'MilitaryParade', 'Mixing', 'MoppingFloor', 'Nunchucks', 'ParallelBars', 'PizzaTossing',\n",
    "              'PlayingGuitar', 'PlayingPiano', 'PlayingTabla', 'PlayingViolin', 'PlayingCello', 'PlayingDaf',\n",
    "              'PlayingDhol', 'PlayingFlute', 'PlayingSitar', 'PoleVault', 'PommelHorse', 'PullUps', 'Punch',\n",
    "              'PushUps', 'Rafting', 'RockClimbingIndoor', 'RopeClimbing', 'Rowing', 'SalsaSpin', 'ShavingBeard',\n",
    "              'Shotput', 'SkateBoarding', 'Skiing', 'Skijet', 'SkyDiving', 'SoccerJuggling', 'SoccerPenalty',\n",
    "              'StillRings', 'SumoWrestling', 'Surfing', 'Swing', 'TableTennisShot', 'TaiChi', 'TennisSwing',\n",
    "              'ThrowDiscus', 'TrampolineJumping', 'Typing', 'UnevenBars', 'VolleyballSpiking', 'WalkingWithDog',\n",
    "              'WallPushups', 'WritingOnBoard', 'YoYo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ApplyEyeMakeup\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:/Users/Fletcher/Documents/McDaniel/Summer 2019 research/Python Code/Images-VideosApplyEyeMakeup'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-263c58df77fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mvideo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathVid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mpathImg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpathVid\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m#print(video)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:/Users/Fletcher/Documents/McDaniel/Summer 2019 research/Python Code/Images-VideosApplyEyeMakeup'"
     ]
    }
   ],
   "source": [
    "testing_data1 = []\n",
    "catNum = 0\n",
    "count = 0\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    # limit to a certain number of categories, later use all categories\n",
    "    if(catNum > 9):\n",
    "        break\n",
    "    \n",
    "    pathCat = os.path.join(TestFrames1DIR, category)\n",
    "    pathVid = TestFrames1DIR + str(category)\n",
    "    print(category)\n",
    "    \n",
    "    for video in os.listdir(pathVid): \n",
    "        pathImg = pathVid + '/' + str(video)\n",
    "        #print(video)\n",
    "        \n",
    "        frame_set = []\n",
    "        \n",
    "        for img in os.listdir(pathImg):\n",
    "            img_array = cv2.imread(pathImg + '/' + img)\n",
    "            \n",
    "            frame_set.append([np.array(img_array), catNum])\n",
    "            \n",
    "        testing_data1.append([np.array(frame_set), catNum])\n",
    "            \n",
    "    catNum += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, label in testing_data1:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "print(X.shape)\n",
    "print(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X /= 255.0\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(?, 227, 227, 3) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input tensor for the CNN\n",
    "input1 = tf.keras.Input( shape=(227,227,3,) )\n",
    "input1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing adding the 20 frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## almost working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first convolutional layer\n",
    "# !!! kinda confused if 'filters' parameter is number of filters or size of each. assumed it is number. !!!\n",
    "# should each output shape 55x55x96\n",
    "\n",
    "frames = []\n",
    "\n",
    "for entry in X:    # the 20 frame array\n",
    "    for frame in entry:\n",
    "        frame_ = tf.keras.layers.Conv2D(96, 11, input_shape=(3, 227, 227), strides=4, activation='relu' )(frame)\n",
    "        frames += frame_\n",
    "\n",
    "\n",
    "# add the 20 frames into each other\n",
    "# should output shape 55x55x96 \n",
    "added = tf.keras.layers.Add()( frames )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this is the rest of the network, but can't test until input works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v1.keras.layers' has no attribute 'LayerNormalization'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c5881d6e6b68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# normalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnorm1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayerNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0madded\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# first pooling layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpool1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPool2D\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnorm1\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v1.keras.layers' has no attribute 'LayerNormalization'"
     ]
    }
   ],
   "source": [
    "# normalization\n",
    "norm1 = layers.LayerNormalization()( added )\n",
    "# first pooling layer\n",
    "pool1 = layers.MaxPool2D( pool_size=3, strides=2 )( norm1 )\n",
    "\n",
    "# first 2D convolutional\n",
    "conv2 = layers.Conv2D( filters=23, kernel_size=256, strides=1 )( pool1 )\n",
    "# normalization\n",
    "norm2 = layers.LayerNormalization()(conv2)\n",
    "# second pooling\n",
    "pool2 = layers.MaxPool2D( pool_size=3, strides=2 )( norm2 )\n",
    "\n",
    "# third convolutional layer\n",
    "conv3 = layers.Conv2D( filters=9, kernel_size=384, strides=1 )( pool2 )\n",
    "# fourth convolutional\n",
    "conv4 = layers.Conv2D( filters=7, kernel_size=384, strides=1 )( conv3 )\n",
    "# fifth convolutional\n",
    "conv5 = layers.Conv2D( filters=5, kernel_size=256, strides=1 )( conv4 )\n",
    "\n",
    "# third pooling\n",
    "pool3 = layers.MaxPool2D( pool_size=3, strides=2 )( conv5 )\n",
    "\n",
    "# \n",
    "#model.add(Flatten())\n",
    "\n",
    "# three fully-connected layers\n",
    "fc1 = layers.Dense( units=2048 )( pool3 )\n",
    "fc2 = layers.Dense( units=2048 )( fc1 )\n",
    "fc3 = layers.Dense( units=101 )( fc2 )\n",
    "\n",
    "# softmax\n",
    "soft = layers.Activation( 'softmax' )( fc3 )\n",
    "\n",
    "model = tf.keras.Model( inputs=inputs, outputs=soft )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
